# Algorithms-for-Optimization-Python
Unofficial implementation in Python porting of the book "[Algorithms for Optimization](https://mitpress.mit.edu/books/algorithms-optimization)" (2019); MIT Press by Mykel J. Kochenderfer and Tim A. Wheeler

![AlgOptBook](https://mitpress.mit.edu/sites/default/files/styles/large_book_cover/http/mitp-content-server.mit.edu%3A18180/books/covers/cover/%3Fcollid%3Dbooks_covers_0%26isbn%3D9780262039420%26type%3D.jpg?itok=hx-SOZVN)

# Contents
## [02. Derivatives in Multiple Dimensions](./Ch%2002.%20Derivatives%20in%20Multiple%20Dimensions.ipynb)
* Symbolic differentiation
* Numerical differentiation
  * Finite difference methods
  * Complex step method
* Automatic differentiation
  * Forward accumulation
  * Reverse accumulation

## [03. Bracketing](./Ch%2003.%20Bracketing.ipynb)
* Unimodality assumption
* Fibonacci search
* Golden section search
* Quadratic fit search
* Shubert-Piyavskii method
* Bisection method

## [04. Local Descent](./Ch%2004.%20Local%20Descent.ipynb)
* Line search
* Approximate line search
  * First Wolfe condition
  * Second Wolfe condition
  * Strong Wolfe condition
* Trust region method

## [05. First-order Methods](./Ch%2005%20First-order%20Methods.ipynb)
* Gradient descent
* Conjugate gradient descent
* Momentum
* Nesterov momentum
* Adagrad
* RMSProp
* Adadelta
* Adam
* Hypergradient descent
* Hypergradient Nesterov momentum

---
* Author: Seok-Ju Hahn
* Email: seokjuhahn@unist.ac.kr
