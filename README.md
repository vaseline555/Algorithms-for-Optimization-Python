# Algorithms for Optimization - Python
Unofficial implementation in Python porting of the book "[Algorithms for Optimization](https://mitpress.mit.edu/books/algorithms-optimization)" (2019); MIT Press by Mykel J. Kochenderfer and Tim A. Wheeler

![AlgOptBook](https://mit-press-us.imgix.net/covers/9780262039420.jpg?auto=format&w=298&dpr=1&q=20)

# Contents
## [02. Derivatives in Multiple Dimensions](./Ch%2002.%20Derivatives%20in%20Multiple%20Dimensions.ipynb)
* Symbolic differentiation
* Numerical differentiation
  * Finite difference methods
  * Complex step method
* Automatic differentiation
  * Forward accumulation
  * Reverse accumulation

## [03. Bracketing](./Ch%2003.%20Bracketing.ipynb)
* Unimodality assumption
* Fibonacci search
* Golden section search
* Quadratic fit search
* Shubert-Piyavskii method
* Bisection method

## [04. Local Descent](./Ch%2004.%20Local%20Descent.ipynb)
* Line search
* Approximate line search
  * First Wolfe condition
  * Second Wolfe condition
  * Strong Wolfe condition
* Trust region method

## [05. First-order Methods](./Ch%2005%20First-order%20Methods.ipynb)
* Gradient descent
* Conjugate gradient descent
* Momentum
* Nesterov momentum
* Adagrad
* RMSProp
* Adadelta
* Adam
* Hypergradient descent
* Hypergradient Nesterov momentum

---
* Implemented by: Seok-Ju Hahn (vaseline555)
* Email: seokjuhahn@unist.ac.kr
